% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/blob_write.R
\name{blob_write}
\alias{blob_write}
\title{Write data frame to Microsoft Azure Data Storage container}
\usage{
blob_write(df, name, stage = c("dev", "prod"), container = "projects")
}
\arguments{
\item{df}{Data frame or simple features to save out.}

\item{name}{Name of the file to write, including prefix (`input/` or `output/`)
and filetype `.parquet`.}

\item{stage}{Store to access, either `dev` (default) or `prod`.}

\item{container}{Container name (`character`) or actual container class object to read from}
}
\value{
Nothing, but file is written to selected container
}
\description{
A convenient file saver that saves the data frame to the specified
parquet file. Simply writes out the data frame based on the file extension and
uploads that to the MADS container using [AzureStor::upload_blob()].
Currently supports Apache Parquet, CSV, GeoJSON, and JSON files.
}
\details{
Files written out based on file type:

* Apache Parquet: [arrow::write_parquet()]
* CSV: [readr::write_csv()]
* GeoJSON: [sf::st_write()]
* JSON: [jsonlite::write_json()]

If `hs_local()`, the file is not uploaded to the container.
}
