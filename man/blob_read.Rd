% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/blob_read.R
\name{blob_read}
\alias{blob_read}
\title{Read a Parquet file stored in Microsoft Azure Data Storage container}
\usage{
blob_read(name, stage = c("prod", "dev"), container = "projects")
}
\arguments{
\item{name}{Name of the file to read, including directory prefixes (`input/` or `output/`)
and file extension, such as `.parquet`.}

\item{container}{Container name (`character`) or actual container class object to read from, either `prod`, `dev`, or `wfp`.}
}
\value{
Data frame.
}
\description{
Reads a file from the `hdx-signals` container.
The file is read based on its prefix in `name`. Currently, the only support is for
Apache Parquet, CSV, GeoJSON and JSON files, but other support can be added if necessary.
}
\details{
Function parsing is done based on file type:

* Apache Parquet: [arrow::write_parquet()].
* CSV: [readr::read_csv()]
* Excel: [readxl::read_excel()]
* GeoJSON: [sf::st_read()]
* JSON: [jsonlite::read_json()]
}
\examples{
df <- blob_read(name = "ds-aa-afg-drought/raw/vector/wfp-chirps-adm2.csv", stage = "dev", container = "projects")

}
